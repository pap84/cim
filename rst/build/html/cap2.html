

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Fundamentos básicos del procesamiento de imágenes &mdash; documentación de Curso de imágenes médicas - 1.0</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Índice"
              href="genindex.html"/>
        <link rel="search" title="Búsqueda" href="search.html"/>
    <link rel="top" title="documentación de Curso de imágenes médicas - 1.0" href="index.html"/>
        <link rel="prev" title="Introducción al transporte de radiación" href="cap1.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Curso de imágenes médicas
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="cap1.html">Introducción al transporte de radiación</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Fundamentos básicos del procesamiento de imágenes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduccion-al-procesamiento-de-imagenes">Introducción al procesamiento de imágenes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#formato-de-imagen-y-representacion-digital">Formato de imagen y representación digital</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#bandas-en-imagenes-digitales">Bandas en imágenes digitales</a></li>
<li class="toctree-l3"><a class="reference internal" href="#representacion-digital-mapa-de-bits-bitmaps">Representación digital: mapa de bits (Bitmaps)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#representacion-digital-imagenes-vectoriales">Representación digital: imágenes vectoriales</a></li>
<li class="toctree-l3"><a class="reference internal" href="#modificacion-de-colores-en-imagenes">Modificación de colores en imágenes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#histograma-de-una-imagen">Histograma de una imagen</a></li>
<li class="toctree-l3"><a class="reference internal" href="#resolucion-de-una-imagen">Resolución de una imagen</a></li>
<li class="toctree-l3"><a class="reference internal" href="#resolucion-tamano-de-imagen-y-tamano-de-archivo">Resolución, tamaño de imagen y tamaño de archivo</a></li>
<li class="toctree-l3"><a class="reference internal" href="#contraste-en-una-imagen">Contraste en una imagen</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#vinculo-fisico-del-origen-de-imagenes">Vínculo físico del origen de imágenes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#modificacion-de-una-imagen">Modificación de una imagen</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#modificacion-de-colores-o-tonalidades-correccion">Modificación de colores o tonalidades: Corrección <span class="math notranslate">\(\gamma\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#modificacion-de-imagen-inversion-flip">Modificación de imagen: inversión (<em>flip</em>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#modificacion-de-imagen-reflexion-mirror">Modificación de imagen: reflexión (<em>mirror</em>)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#modificacion-de-imagen-interpolacion">Modificación de imagen: interpolación</a></li>
<li class="toctree-l3"><a class="reference internal" href="#comparacion-cualitativa-de-performance-de-algoritmos-de-interpolacion">Comparación cualitativa de performance de algoritmos de interpolación</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#relaciones-basicas-entre-pixels">Relaciones básicas entre pixels</a></li>
<li class="toctree-l2"><a class="reference internal" href="#operadores-sobre-imagenes">Operadores sobre imágenes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#adicion-y-diferencia-de-imagenes">Adición y diferencia de imágenes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#operaciones-sobre-pixels">Operaciones sobre pixels</a></li>
<li class="toctree-l2"><a class="reference internal" href="#transformadas-dicretas-la-transformada-de-fourier">Transformadas dicretas: La transformada de Fourier</a></li>
<li class="toctree-l2"><a class="reference internal" href="#filtros">Filtros</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#filtros-de-paso-de-banda">Filtros de paso de banda</a></li>
<li class="toctree-l3"><a class="reference internal" href="#filtros-de-suavizado">Filtros de suavizado</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mascaras-para-filtrado">Máscaras para filtrado</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Curso de imágenes médicas</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Fundamentos básicos del procesamiento de imágenes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/cap2.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="fundamentos-basicos-del-procesamiento-de-imagenes">
<h1>Fundamentos básicos del procesamiento de imágenes<a class="headerlink" href="#fundamentos-basicos-del-procesamiento-de-imagenes" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Una vez presentadas las bases físicas que dan lugar a la formación de
las imágenes radiológicas, en el presente Capítulo se introducirán los
primeros conceptos básicos y la formulación matemática necesaria para un
acercamiento al procesamiento de imágenes digitales. Así, se introducirá
al lector en las primeras nociones para lograr comprender la
representación y las operaciones elementales del procesamiento digital
de imágenes.</p>
<div class="section" id="introduccion-al-procesamiento-de-imagenes">
<h2>Introducción al procesamiento de imágenes<a class="headerlink" href="#introduccion-al-procesamiento-de-imagenes" title="Enlazar permanentemente con este título">¶</a></h2>
<p>El análisis y procesamiento de imágenes se realiza a través de
computadoras, debido a la complejidad y el número de cálculos necesarios
para realizarlo. Es por esto que, si bien la formulación matemática
necesaria para su realización data de varios siglos atrás, la
posibilidad real de utilizarla de forma cotidiana en la práctica clínica
ha sido posible recién en las últimas décadas, gracias al avance en las
tecnologías del hardware.</p>
<p>La proliferación de nuevos equipamientos con capacidad para realizar
millones de operaciones por segundo y su extensión a la vida cotidiana y
a todo tipo de usuario, ha hecho posible que el análisis y procesamiento
de imágenes digitales se constituya en un gran campo de estudio. En la
actualidad, esta tecnología se encuentra incorporada incluso en todo
tipo de equipamiento doméstico, como cámaras digitales, scaners y
teléfonos celulares, entre otros.</p>
<p>En términos históricos, la utilización de imágenes radiográficas para
diagnóstico clínico data prácticamente desde el descubrimiento de los
rayos X en 1895 (Röentgen). Incluso, las imágenes funcionales a partir
de la emisión de fotones (rayos <span class="math notranslate">\(\gamma\)</span>) por parte de
radionucleidos ya cuenta con más de 90 años de antigüedad (Heavesy &amp;
Seaborg, 1924). Sin embargo, las imágenes eran adquiridas sobre films
radiográficos o directamente <em>in vivo</em>, por lo que su correcto
procesamiento no ha explotado su real potencialidad sino hasta la
incorporación de la tecnología que permitió digitalizarlas.</p>
<p>El motivo principal de esta “aparición tardía” del procesamiento de
imágenes ha sido entonces, debido a los requerimientos de hardware tanto
para el procesamiento de las mismas como para la representación de estas
en sistemas gráficos de alta performance. Paralelamente a este
desarrollo, la formulación de algoritmos para el procesamiento ha
seguido los avances tecnológicos logrando un alto grado de sofisticación
y manipulación de imágenes en tiempo casi real.</p>
<p>La variedad actual de técnicas, algoritmos y desarrollos de software y
hardware utilizados en el procesamiento de imágenes digitales escapa al
alcance de cualquier curso. En ellos se aprovechan técnicas
desarrolladas inicialmente sobre conceptos fundacionales para el
análisis de imágenes, y se incorporan conceptos y nociones de los más
variados, propios de la física y la matemática, como el caso de la
entropía o la métrica.</p>
<p>En el presente capítulo se introducirán las primeras nociones y
conceptos para abordar el estudio del procesamiento de imágenes
digitales, entre los que se cuentan las formatos de lectura y
representación de imágenes, las operaciones de modificación, las
transformaciones sobre tonalidades y colores, y la generación de efectos
sobre regiones de una imagen.</p>
<p>El interés del siguiente estudio puede condensarse en dos objetivos
principales: a) lograr una mejora considerable de la calidad de la
imagen para la interpretación de un especialista, y/o b) lograr la
obtención de información específica para su procesamiento por medio de
sistemas de cálculo y análisis.</p>
<p>Serán de interés de este curso, las imágenes producidas por interacción
de la radiación ionizante con la materia para uso médico, es decir
aquellas adquiridas por detectores de rayos X o <span class="math notranslate">\(\gamma\)</span> <a class="footnote-reference" href="#id7" id="id1">[1]</a> y
que hayan atravesado -o partido de- tejido biológico de un paciente,
formando una imagen bidimensional (2D) o tridimensional (3D).</p>
</div>
<div class="section" id="formato-de-imagen-y-representacion-digital">
<h2>Formato de imagen y representación digital<a class="headerlink" href="#formato-de-imagen-y-representacion-digital" title="Enlazar permanentemente con este título">¶</a></h2>
<p>En la actualidad, las imágenes constituyen un lenguaje en sí mismas.
Dependiendo de diferentes factores culturales, las imágenes son
utilizadas para transmitir mensajes, símbolos y distintos tipos de
información. Por esto, es necesario contar con un soporte para la
representación digital de las imágenes que permita luego modificar el
mismo a fin de o bien modificar el contenido visual y simbólico u
obtener información necesaria.</p>
<div class="section" id="bandas-en-imagenes-digitales">
<h3>Bandas en imágenes digitales<a class="headerlink" href="#bandas-en-imagenes-digitales" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Para lograr adquirir una imagen, de forma remota, debe existir algún
tipo de interacción entre el objeto que se desea observar y el detector.
En las imágenes digitales, los distintos tipos de detector dependen del
tipo de radiación electromagnética que son capaces de detectar. Así como
la información que se puede obtener de un objeto depende también de la
interacción de esta radiación con el objeto. De esta particularidad
proviene el concepto de “bandas”, donde se divide el espectro
electromagnético en función de los tipos de interacción de la radiación
con la materia (ver Fig. <a class="reference external" href="#fig2-1">[fig2-1]</a>), lo que define desde
los objetos a analizar hasta los detectores y materiales que pueden
utilizarse.</p>
<p>Todos los objetos absorben, reflejan o emiten cuantos de energía
dependiendo de su longitud de onda, intensidad y tipo de radiación. Este
tipo de radiación se define a partir de sus propiedades físicas dentro
del espectro electromagnético. El ojo humano, por su parte, solo es
capaz de detectar energía electromagnética en el espectro de luz
visible, mientras que para los rayos X, la radiación ultravioleta,
infrarroja o de microondas, es necesaria la construcción de detectores
que puedan recabar esta información, ya sea de forma digital o
analógica, para poder ser cuantificada y analizada.</p>
<div class="figure align-center" id="id13">
<img alt="_images/figure_1.png" src="_images/figure_1.png" />
<p class="caption"><span class="caption-text"><strong>Figura 1:</strong> Esquema cualitativo del espectro electromagnético</span></p>
</div>
</div>
<div class="section" id="representacion-digital-mapa-de-bits-bitmaps">
<h3>Representación digital: mapa de bits (Bitmaps)<a class="headerlink" href="#representacion-digital-mapa-de-bits-bitmaps" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Un Bitmap es un modo elemental para representar imágenes digitales como
información en el <em>hardware</em>, específicamente la memoria, de un
computador. Consiste, básicamente, en formar arreglos de elementos
(vectores, matrices, tensores) ordenados de modos específicos. En
general, para el caso típico de imágenes 2D, se realiza un ordenamiento
por filas de elementos de matriz (<em>pixels</em>) asignando a cada uno un
valor que determina “el color” en esa posición de la imagen.</p>
<p>En el caso de imágenes en tonalidades de grises, el valor del elemento
de matriz es un escalar; mientras que para el caso de imágenes a color
el valor de cada elemento de matriz es un vector de tres coordenadas,
cada una de las cuales especifica “el grado de influencia” de los
colores rojo (Red “R”), verde (Green “G”) y azul (Blue “B”), de modo que
se denomina representación RGB). Existen otros modos de representación a
color, como por ejemplo CMYK (cián, magenta, amarillo y negro).</p>
<p>Típicamente se emplean escalas (que determinan “rangos dinámicos”) en
<span class="math notranslate">\(2^{N}\)</span> bits, y se denomina <span class="math notranslate">\(N-\)</span> bits. Es decir, para el
caso más común de 8-bits, la escala es <span class="math notranslate">\([0, 255]\)</span>, ya que por
costumbre se define el rango como <span class="math notranslate">\([0, 2^{N} - 1]\)</span>.</p>
<p>El uso típico de 8-bits está basado, principalmente, en dos motivos. En
primer lugar, estudios biométricos muestran que el ojo humano no es
suficientemente sensible para diferenciar más de 256 niveles de
intensidad para un dado color. Además, el rango de valores para los
elementos de matriz determinan las necesidad en cuanto a la capacidad de
almacenamiento en el computador.</p>
<p>Entonces, para imágenes en tonalidades de grises, conocidas como “de una
banda” el rango para los valores de los elementos de matriz (escalares)
es <span class="math notranslate">\([0, 255]\)</span>, mientras que para imágenes a color, los valores de
elementos de matriz (vectores de 3 coordenadas) asumen valores en
<span class="math notranslate">\(([0, 255], [0, 255], [0, 255])\)</span>. Si embargo, también es frecuente
encontrar representaciones normalizadas para imágenes a color, es decir,
elementos de matriz en <span class="math notranslate">\(([0, 1], [0, 1], [0, 1])\)</span> para determinar
los colores RGB.</p>
<p>Todos los colores en el rango visible pueden representarse como
combinaciones RGB, variando desde el negro <span class="math notranslate">\((0, 0, 0)\)</span> al blanco
<span class="math notranslate">\((255, 255, 255)\)</span>. Por lo tanto, una imagen RGB es representada
por un arreglo bidimensional de <em>pixels</em>, cada uno codificado en 3 bytes
pudiendo asumir <span class="math notranslate">\(256^{3}\)</span> diferentes valores de combinaciones
vectoriales, es decir 16.8 millones de diferentes colores,
aproximadamente.</p>
</div>
<div class="section" id="representacion-digital-imagenes-vectoriales">
<h3>Representación digital: imágenes vectoriales<a class="headerlink" href="#representacion-digital-imagenes-vectoriales" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Las imágenes vectoriales están constituidas por contornos y rellenos
definidos matemáticamente, vectorialmente, por medio de ecuaciones que
describen perfectamente cada ilustración. De este modo, es posible
implementar <em>scaling</em> sin pérdida de calidad. El proceso de <em>scaling</em> es
típico en la formación, producción o reproducción en dispositivos. Por
ello, la importancia de mantener la invariabilidad. Esta característica
resulta de particular relevancia en casos que las ilustraciones
contengan marcadas zonas con contornos curvados, ya que el pixelado
implicaría una pérdida de resolución, como indica la figura .</p>
<div class="figure align-center" id="id14">
<img alt="_images/Fig2_1.png" src="_images/Fig2_1.png" />
<p class="caption"><span class="caption-text"><strong>Figura 2:</strong> Imagen en representación vectorial (izquierda) y en pixelado bitmap (derecha).</span></p>
</div>
</div>
<div class="section" id="modificacion-de-colores-en-imagenes">
<h3>Modificación de colores en imágenes<a class="headerlink" href="#modificacion-de-colores-en-imagenes" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Es posible cuantificar la diferencia entre dos colores (en
representación digital, valores del trio vectorial RGB) calculando la
distancia, según algún tipo de métrica, Euclidea por ejemplo, entre los
vectores que los representan.</p>
<p>Se el color <span class="math notranslate">\(C_{1}\)</span> representado por el vector
<span class="math notranslate">\((R_{1}, G_{1}, B_{1})\)</span> y el color <span class="math notranslate">\(C_{2}\)</span> representdo por
<span class="math notranslate">\((R_{2}, G_{2}, B_{2})\)</span>. Entonces, en el espacio vectorial, la
distancia <span class="math notranslate">\(D (C_{1}, C_{2})\)</span> entre éstos está dada por:</p>
<div class="math notranslate">
\[\begin{aligned}
    D(C_{1}, C_{2}) = \sqrt{ \left(R_{1} - R_{2} \right)^{2} + \left(G_{1} - G_{2} \right)^{2} + \left(B_{1} - B_{2} \right)^{2}}
\label{EqXXII}\end{aligned}\]</div>
<p>Para el caso particular de imágenes de una banda (tonalidades de grises)
puede aplicar la misma metodología descrita para imágenes RGB con la
simplificación asociada al hecho de que en el espacio de colores, los
vectores en la dirección del vector <span class="math notranslate">\((1, 1, 1)\)</span> representan las
diferentes tonalidades de gris.</p>
<p>Por tanto, existe la equivalencia de que para cualquier <em>pixel</em> de tipo
RGB <span class="math notranslate">\((R, G, B)\)</span> si se lo proyecta sobre <span class="math notranslate">\((1, 1, 1)\)</span> se
obtiene la contribución de cada tonalidad de gris. Entonces, se tiene:</p>
<div class="math notranslate">
\[\begin{aligned}
    Proy \equiv (R, G, B) \cdot (1, 1, 1) =R + G + B = \lvert \vec{V} \rvert \lvert \hat{n} \rvert cos(\phi)
\label{EqXXIIb}\end{aligned}\]</div>
<p>donde <span class="math notranslate">\(Proy\)</span> es la proyección, <span class="math notranslate">\(\vec{V}\)</span> es el vector que
forma el punto <span class="math notranslate">\((R, G, B)\)</span> en el espacio de coordenadas del trío
(representación vectorial), <span class="math notranslate">\(\hat{n}\)</span> es el versor de proyección
<span class="math notranslate">\((1, 1, 1)\)</span> y <span class="math notranslate">\(\phi\)</span> es el ángulo que forma <span class="math notranslate">\(\vec{V}\)</span>
con <span class="math notranslate">\(\hat{n}\)</span>.</p>
<p>De aquí puede verse que <span class="math notranslate">\(Proy = \frac{R + G + B}{\sqrt{3}}\)</span> y debe
atenderse de que este valor no exceda 255, de modo que es usual
renormalizar para obtener <span class="math notranslate">\(Proy = \frac{R + G + B}{3}\)</span></p>
<p>A modo de ilustración de los conceptos generales expuestos sobre
representaciones vectoriales-bitmap, se propone un caso de aplicación
muy sencillo. Si el objetivo en la detección de bordes (orillas) de las
formas en una imagen para obtener el bitmap resultante que resalte los
bordes en blanco-negro, puede procederse del siguiente modo: Desplazarse
dentro de la imagen <em>pixel</em> a <em>pixel</em> comparando el color de cada uno
con su vecino de la derecha y su vecino de abajo. Luego, se efectúa el
siguiente control (criterio): si al comparar resulta en una diferencia
muy grande (“muy grande” es un parámetro <a class="footnote-reference" href="#id8" id="id2">[2]</a> o conjunto de parámetros
pre-definidos por el usuario, o bien automatizados en casos más
elaborados) el <em>pixel</em> en consideración forma parte del borde y se le
asigna el color blanco, de otro modo se asigna el color negro.</p>
</div>
<div class="section" id="histograma-de-una-imagen">
<h3>Histograma de una imagen<a class="headerlink" href="#histograma-de-una-imagen" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Dada la representación digital de una imagen por medio del arreglo de
<span class="math notranslate">\(N\)</span> filas por <span class="math notranslate">\(M\)</span> columnas se determina una matriz
<span class="math notranslate">\(M \times N\)</span>, en la cual la representación digital de bitmap
estará dada por la función distribución <span class="math notranslate">\(f(m, n)\)</span>, para
<span class="math notranslate">\(n \in [0, N-1]\)</span> y <span class="math notranslate">\(m \in [0, M-1]\)</span>, típicamente <span class="math notranslate">\(N\)</span> y
<span class="math notranslate">\(M\)</span> son potencias de 2, como ya se enunció.</p>
<p>El histograma de una imagen <span class="math notranslate">\(h(i)\)</span>, comúnmente denominado <em>“image
enhancenment”</em> o <em>“image characterization”</em> es un vector que da cuenta
de la cantidad de <em>pixels</em> dentro de la imagen con un cierto valor de
elemento. Es decir, para una imagen de <span class="math notranslate">\(\alpha\)</span>-bits, se tiene:</p>
<div class="math notranslate">
\[\begin{aligned}
    h(i) \equiv \sum _{m=0}^{M-1} \, \; \sum _{n=0}^{N-1} \delta(f(n, m) - i) \; \, \; \forall i \in [0, 2^{\alpha}-1]
\label{EqXXIII}\end{aligned}\]</div>
<p>Una de las técnicas genéricas, que luego se diversifica a una cantidad
muy variada de metodologías específicas de procesamiento, es el método
de convolución. Sea <span class="math notranslate">\(w(k, l)\)</span> un arreglo
<span class="math notranslate">\(2 \times K + 1, 2 \times L + 1\)</span>, centrado en el “origen”
<span class="math notranslate">\((0, 0)\)</span> que coincide con el <em>pixel</em> central de la imagen. Puede
considerarse a <span class="math notranslate">\(w(k, l)\)</span> como un <em>kernel</em> de convolución de modo
que aplicado a la imagen <span class="math notranslate">\(f(n, m)\)</span> resulte:</p>
<div class="math notranslate">
\[\begin{aligned}
    g(m, n) \equiv w(k, l) \ast f(m, n) = \sum _{k=-K}^{K} \, \; \sum _{l=-L}^{L} w(k, l) \cdot f(m-k, n-l)
\label{EqXXIV}\end{aligned}\]</div>
<p>A partir de esta definición, pueden introducirse una gran cantidad de
métodos específicos, entre los que se destacan las transformadas, como
Fourier, Laplace, Radon, etc.</p>
</div>
<div class="section" id="resolucion-de-una-imagen">
<h3>Resolución de una imagen<a class="headerlink" href="#resolucion-de-una-imagen" title="Enlazar permanentemente con este título">¶</a></h3>
<p><em>A priori</em>, este concepto tiene diferentes acepciones según el contexto
en el que se utilice y se podría definir, de modo genérico, como la
capacidad para representar o percibir los detalles de una imagen. Se
trata de un concepto presente en todo el proceso digital, desde la
captura o generación hasta la representación, y afecta (condiciona) el
procesamiento posterior.</p>
<p>Una definición útil es: la resolución de una imagen es la cantidad de
<em>pixels</em> que la describen. Y una medida típica es en términos de
“<em>pixels</em> por pulgada” (ppi). Por tanto, la calidad de la representación
así como el tamaño de la imagen dependen de la resolución, que determina
a su vez los reqerimientos de memoria para el archivo gráfico a generar.</p>
</div>
<div class="section" id="resolucion-tamano-de-imagen-y-tamano-de-archivo">
<h3>Resolución, tamaño de imagen y tamaño de archivo<a class="headerlink" href="#resolucion-tamano-de-imagen-y-tamano-de-archivo" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Los tres conceptos están estrechamente relacionados y dependen
mutuamente, aunque se refieren a características diferenciadas y debe
evitarse la confusión.</p>
<p>El tamaño de una imagen son sus dimensiones reales en términos de
anchura y altura una vez impresa, mientras que el tamaño del archivo se
refiere a la cantidad de memoria física necesaria para almacenar la
información de la imagen digitalizada en cualquier soporte informático
de almacenamiento.</p>
<p>Ciertamente, la resolución de la imagen condiciona fuertemente estos dos
conceptos, ya que la cantidad de <em>pixels</em> de la imagen digitalizada es
fijo y por tanto al aumentar el tamaño de la imagen se reduce la
resolución y viceversa.</p>
<p>A modo de ejemplo: duplicando la resolución de una imagen digitalizada,
de 50 ppi a 100 ppi, el tamaño de la imagen se reduce a la cuarta parte
del original mientras que dividir la resolución por 2. Es decir, se pasa
de 300 ppi a 150 ppi obteniendo una imagen con el doble de las
dimensiones originales que represebtan cuatro veces su superficie.</p>
<p>La reducción de la resolución de la imagen, manteniendo su tamaño,
provoca eliminación de <em>pixels</em>. Entonces, se obtiene una representación
(descripción) menos precisa de la imagen, así como transiciones de color
más bruscas. El tamaño del archivo que genera una imagen digitalizada es
proporcional, como se espera, a la resolución, por lo tanto, variarla
implica modificar en el mismo sentido el tamaño del archivo.</p>
</div>
<div class="section" id="contraste-en-una-imagen">
<h3>Contraste en una imagen<a class="headerlink" href="#contraste-en-una-imagen" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Conceptualmente, aumentar o disminuir el contraste en una imagen
consiste, básica y visualmente, en aumentar o disminuir la pendiente de
la linea recta con pendiente a 45 grados que representa los grises (con
la precaución de no exceder los límites 0-255) entre <em>input</em> y <em>output</em>,
como indica la figura <a class="reference external" href="#Fig2_2">[Fig2_2]</a>.</p>
<p>La transformación correspondiente al cambio de contraste es:</p>
<div class="math notranslate">
\[\begin{aligned}
    V_{O}(m, n) = \left( V_{I}(m, n) - 2^{Y - 1} \right) \, \tan{\phi} \, + 2^{Y - 1}
\label{EqXXV}\end{aligned}\]</div>
<p>donde <span class="math notranslate">\(Y\)</span> es la escala en bits, <span class="math notranslate">\(V_{I}\)</span> y <span class="math notranslate">\(V_{O}\)</span> son
los valores de <em>input</em> y <em>output</em>, respectivamente valuados en el pixel
<span class="math notranslate">\((m, n)\)</span>; y el ángulo <span class="math notranslate">\(\phi\)</span> cooresponde a las propiedades
de la transformación lineal de contrastes, específicamente la pendiente
(figura <a class="reference external" href="#Fig2_2">[Fig2_2]</a>).</p>
<div class="figure align-center" id="id15">
<img alt="_images/Fig2_2.png" src="_images/Fig2_2.png" />
<p class="caption"><span class="caption-text"><strong>Figura 3:</strong> Representación del cambio de contraste entre <em>input</em> y <em>output</em>.</span></p>
</div>
</div>
</div>
<div class="section" id="vinculo-fisico-del-origen-de-imagenes">
<h2>Vínculo físico del origen de imágenes<a class="headerlink" href="#vinculo-fisico-del-origen-de-imagenes" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Las imágenes generadas por radiación electromagnética pueden clasifcarse
en modo genérico según el ordenamiento de mayor a menor frecuencia.</p>
<dl class="docutils">
<dt>Rayos <span class="math notranslate">\(\gamma\)</span></dt>
<dd>medicina nuclear, observaciones de astronomía.</dd>
<dt>Rayos X</dt>
<dd>diagnóstico médico e industria (control de calidad).</dd>
<dt>Banda ultravioleta</dt>
<dd>Inspección industrial y microscopía biológica.</dd>
<dt>Banda visible e infrarroja</dt>
<dd>Aplicaciones varias, fotografía.</dd>
<dt>Microondas</dt>
<dd>radar.</dd>
<dt>Ondas de radio</dt>
<dd>medicina (MRI) y algunas aplicaciones en astronomía.</dd>
</dl>
</div>
<div class="section" id="modificacion-de-una-imagen">
<h2>Modificación de una imagen<a class="headerlink" href="#modificacion-de-una-imagen" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Una imagen <em>input</em> puede ser modifica por medio de diferentes maneras,
según la/s propiedad/es que se modifica/n.</p>
<p>En particular, se consideran a continuación algunas de las
modificaciones más frecuentes.</p>
<div class="section" id="modificacion-de-colores-o-tonalidades-correccion">
<h3>Modificación de colores o tonalidades: Corrección <span class="math notranslate">\(\gamma\)</span><a class="headerlink" href="#modificacion-de-colores-o-tonalidades-correccion" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Existe una amplia variedad de técnicas y criterios para modificar los
colores de una imagen. Una de las metodologías más empleada, y sencilla,
es la corrección <span class="math notranslate">\(\gamma\)</span>, definida a partir de:</p>
<div class="math notranslate">
\[\begin{aligned}
    V_{O}(m, n) = \left( 2^{N} - 1 \right) \left( \frac{V_{I}(m, n)}{2^{N} -1} \right)^{\frac{1}{\gamma}}
\label{EqXXVI}\end{aligned}\]</div>
<p>donde el índice <span class="math notranslate">\(\gamma\)</span> asume valores <span class="math notranslate">\(\in \Re\)</span>.</p>
<p>Por lo tanto, resulta:</p>
<ul class="simple">
<li>Para <span class="math notranslate">\(\gamma\)</span> = 1 no hay ninguna corrección.</li>
<li>Para valores de <span class="math notranslate">\(\gamma &gt; 1\)</span> hay una gran corrección en el
contraste para valores pequeños del color de <em>input</em> mientras que una
pequeña corrección en el contraste para valores altos. El brillo
aumenta más para valores intermedios del color de <em>input</em>.</li>
<li>Para valores de <span class="math notranslate">\(\gamma &lt; 1\)</span> hay una pequeña corrección en el
contraste para valores bajos del color de <em>input</em>, mientras que una
gran corrección en el contraste para valores altos. El brillo
disminuye más para valores intermedios del color de <em>input</em>.</li>
</ul>
</div>
<div class="section" id="modificacion-de-imagen-inversion-flip">
<h3>Modificación de imagen: inversión (<em>flip</em>)<a class="headerlink" href="#modificacion-de-imagen-inversion-flip" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Básicamente, esta modificación consiste en una transformación que
produce un “movimiento” de la columna <span class="math notranslate">\(m\)</span>, fila <span class="math notranslate">\(n\)</span> a la
columna <span class="math notranslate">\(m\)</span> y fila <span class="math notranslate">\((n_{max} - n) + 1\)</span>, para <span class="math notranslate">\(n_{max}\)</span>
como la dimensión en la dirección de <span class="math notranslate">\(n\)</span>.</p>
<p>Es decir,</p>
<div class="math notranslate">
\[\begin{aligned}
    V_{flip}(m, n) = V_{I} (m, (n_{max} - n) + 1)
\label{EqXXVII}\end{aligned}\]</div>
<p>donde <span class="math notranslate">\(V_{flip}\)</span> es la matriz de output que corresponde a la
transformación de inversión.</p>
</div>
<div class="section" id="modificacion-de-imagen-reflexion-mirror">
<h3>Modificación de imagen: reflexión (<em>mirror</em>)<a class="headerlink" href="#modificacion-de-imagen-reflexion-mirror" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Básicamente, esta modificación consiste en una transformación que
produce un “movimiento” de la fila <span class="math notranslate">\(n\)</span>, columa <span class="math notranslate">\(m\)</span> a la fila
<span class="math notranslate">\(n\)</span> y columna <span class="math notranslate">\((m_{max} - m) + 1\)</span>, para <span class="math notranslate">\(m_{max}\)</span> como
la dimensión en la dirección de <span class="math notranslate">\(m\)</span>.</p>
<p>Es decir,</p>
<div class="math notranslate">
\[\begin{aligned}
    V_{mirror}(m, n) = V_{I} ((m_{max}  - m) + 1, n)
\label{EqXXVIII}\end{aligned}\]</div>
<p>donde <span class="math notranslate">\(V_{mirror}\)</span> es la matriz de output que corresponde a la
transformación de reflexión.</p>
</div>
<div class="section" id="modificacion-de-imagen-interpolacion">
<h3>Modificación de imagen: interpolación<a class="headerlink" href="#modificacion-de-imagen-interpolacion" title="Enlazar permanentemente con este título">¶</a></h3>
<p>A partir de de un muestreo <em>input</em> pueden estimarse los valores de la
intensidad en puntos diferentes a aquellos puntos donde si se conoce el
valor Entre otras técnicas, se destacan los métodos de <em>re-sampling</em>.</p>
<p>De este modo, se emplean diferentes criterios para determinar los
valores <span class="math notranslate">\(V_{O}(k, l)\)</span> para <em>pixels</em> <span class="math notranslate">\((k, l)\)</span> donde el
<em>input</em> <span class="math notranslate">\(V_{I}\)</span> no es conocido:</p>
<ul class="simple">
<li>Interpolación al vecino más cercano.</li>
<li>Interpolación bilineal.</li>
<li>Interpolación bicúbica.</li>
</ul>
<p>La técnica de interpolacoón al vecino más cercano (<em>Nearest neighbor
interpolation</em>) está basada en superponer el arreglo 2D <em>output</em> al
arreglo 2D <em>input</em> calculando el valor para los <em>pixels</em> <span class="math notranslate">\((k, l)\)</span>
según los valores conocidos <span class="math notranslate">\(V_{I}(i, j)\)</span>, utilizando un promedio
(que puede cuantificarse de diferentes maneras) de los vecinos más
cercanos equidistantes. Sin embargo, puede verse que esta técnica
presenta algunos efectos indeseables.</p>
<p>La tácnica de interpolación lineal considera los 4 <em>pixels</em> más cercanos
a <span class="math notranslate">\(V(k, l)\)</span> para la interpolación. Se realiza un promedio entre
estos 4 valores para determinar el valor desconocido del <em>pixel</em>
<span class="math notranslate">\((k, l)\)</span>. La imagen <em>output</em> resulta más “suave” que para el caso
de la técnica <em>Nearest neighbor interpolation</em>. Pero, puede causar que
la imagen se vea algo “difusa”.</p>
<p>Entonces, los valores de <em>pixels</em> <span class="math notranslate">\((k, l)\)</span>, para los cuales no se
conoce <span class="math notranslate">\(V_{I}(k, l)\)</span> se obtienen a partir de:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    V_{O}(k, l) = (1 - \alpha)\, (1-\beta) \, V_{I}(i,j) + \alpha (1 - \beta) \, V_{I}(i +1, j) + \nonumber \\
    (\alpha -1) \, V_{I}(i, j+1) + \alpha \, \beta \, V_{I}(i +1, j +1)
\label{EqXXIX}\end{aligned}\end{split}\]</div>
<p>donde <span class="math notranslate">\(\alpha \equiv k - i\)</span>, <span class="math notranslate">\(\beta \equiv l -j\)</span>,
<span class="math notranslate">\(i \equiv floor(k)\)</span> y <span class="math notranslate">\(j \equiv floor(l)\)</span> <a class="footnote-reference" href="#id9" id="id3">[3]</a>.</p>
<p>Por su parte, la técnica de interpolación bicúbica Es el algoritmo de
interpolación más utilizado. Considera los 16 <em>pixels</em> más cercanos a
cada <em>pixel</em> <span class="math notranslate">\((k, l)\)</span> cuyo valor debe determinarse por
interpolación. Se aproxima localmente al valor (el nivel de gris) en la
imagen original mediante una superficie polinómica de tipo bicúbica.
Resulta ser, de las técnicas quí descritas, el óptimo al considerar el
balance entre tiempo de cómputo y <em>performance</em>.</p>
<p>La implementación de este método puede llevarse a cabo por medio de
procesar el bloque <span class="math notranslate">\(B(k, l)\)</span>, centraado en el <em>pixel</em>
<span class="math notranslate">\((k, l)\)</span>, cuyas dimensiones se corresponden con las dimensiones de
la máscara (16 <em>pixels</em> en un arreglo 5 <span class="math notranslate">\(\times\)</span> 5):</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    B(k, l) = \sum _{i=0}^{3} \sum _{j=0}^{3} \,
q^{(k, l)}_{i, j} (k - k')^{i} \, (l - l')^{j} \\ \nonumber
\, \, \; \; k', \,  \in [k - 2, k + 2] \; \, \&amp; \;
l' \,  \in [l - 2, l + 2]
\label{EqXXX}\end{aligned}\end{split}\]</div>
<p>donde los coeficientes <span class="math notranslate">\(q_{i, j}\)</span> deben ser determinados. O bien,</p>
<div class="math notranslate">
\[\begin{aligned}
    V_{O}(k, l) = h(k) \, h(l)
\label{EqXXXI}\end{aligned}\]</div>
<p>donde la función de interpolación <span class="math notranslate">\(h\)</span> se define, a trozos, del
siguiente modo:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    h(p) \equiv 1 - \, \lvert p \rvert^{2} + \lvert p \rvert^{3} \; \, \; \forall \lvert p \rvert &lt; 1 \nonumber \\
    h(p) \equiv 4 - \, 8 \, \lvert p \rvert^{2} + 5 \, \lvert p \rvert^{2} - \lvert p \rvert^{3} \; \, \; \forall 1 \leq \lvert p \rvert &lt; 2 \\
    h(p) \equiv 0 \, \; \, \forall p \geq 2 \nonumber
\label{EqXXXII}\end{aligned}\end{split}\]</div>
</div>
<div class="section" id="comparacion-cualitativa-de-performance-de-algoritmos-de-interpolacion">
<h3>Comparación cualitativa de performance de algoritmos de interpolación<a class="headerlink" href="#comparacion-cualitativa-de-performance-de-algoritmos-de-interpolacion" title="Enlazar permanentemente con este título">¶</a></h3>
<ul class="simple">
<li>Interpolación de vecino más cercano: El error de posición resulta, a
los sumo, medio <em>pixel</em>, que es perceptible en objetos con fronteras
rectas en las que aparece un efecto de salto después de de esta
transformación.</li>
<li>Interpolación Lineal: Genera una leve disminución de resolución
debido al borroneo (<em>blurring</em>) intrínseco al modo de cálculo del
valor promedio, pero disminuye el efecto de salto que presenta el
algoritmo de vecino más cercano.</li>
<li>Interpolación Bicúbica: No presenta el problema del efecto de salto a
la vez que genera un menor <em>blurring</em>.</li>
</ul>
</div>
</div>
<div class="section" id="relaciones-basicas-entre-pixels">
<h2>Relaciones básicas entre pixels<a class="headerlink" href="#relaciones-basicas-entre-pixels" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La relación básica más inmediata entre <em>pixels</em> es la distancia
<span class="math notranslate">\(D\)</span> entre dos <em>pixels</em> <span class="math notranslate">\((m, n)\)</span> y <span class="math notranslate">\((m', n')\)</span>.</p>
<p>Los axiomas para definir una métrica o función de distancia entre
<em>pixels</em> <span class="math notranslate">\(D\)</span> requieren de los siguientes criterios:</p>
<ul class="simple">
<li><span class="math notranslate">\(D(k \; k', l \; l') \geq 0\)</span> con
<span class="math notranslate">\(D(k \; k', l \; l') = 0 \Leftrightarrow k=k' \, \; l=l'\)</span></li>
<li><span class="math notranslate">\(D(k \; k', l \; l') = D(k' \; k, l' \; l)\)</span></li>
<li><span class="math notranslate">\(D(k \; k', l \; l') \leq D(k \; k', s \; s') + D(s \; s', l \; l')\)</span></li>
</ul>
<p>A partir de estas condiciones pueden definirse diferentes métricas.
Entre ellas:</p>
<div class="math notranslate">
\[\begin{aligned}
    D(k \; k', l \; l') \equiv \sqrt{\left( k - k' \right)^2 + \left( l - l' \right)^2}
\label{EqXXXIII}\end{aligned}\]</div>
<div class="math notranslate">
\[\begin{aligned}
    D_{4}(k \; k', l \; l') \equiv \lvert k - k' \rvert + \lvert l - l' \rvert
\label{EqXXXIV}\end{aligned}\]</div>
<div class="math notranslate">
\[\begin{aligned}
    D_{8}(k \; k', l \; l') \equiv \max \left( \lvert k - k' \rvert , \lvert l - l' \rvert \right)
\label{EqXXXIV}\end{aligned}\]</div>
<p>Las definiciones Euclidea, <span class="math notranslate">\(D_{4}\)</span> y <span class="math notranslate">\(D_{8}\)</span> para la
distancia entre <em>pixels</em> no depende de adyacencias sino exclusivamente
de las coordenadas espaciales <span class="math notranslate">\((k, l)\)</span>.</p>
<p>Puede verse, a partir de las definiciones de las métricas que la
condición <span class="math notranslate">\(D(k \, k', l \, l') \leq. R\)</span> determina un círculo
centrado en <span class="math notranslate">\((k, l)\)</span> para la métrica Euclidea, un rombo para la
métrica <span class="math notranslate">\(D_{4}\)</span> y un cuadrado para la métrica <span class="math notranslate">\(D_{8}\)</span>.</p>
</div>
<div class="section" id="operadores-sobre-imagenes">
<h2>Operadores sobre imágenes<a class="headerlink" href="#operadores-sobre-imagenes" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Para operar sobre imágenes pueden utilizarse herramientas basadas en
operaciones matriciales de álgebra lineal y operaciones “de array”
orientadas <em>pixel a pixels</em>. <span class="math notranslate">\(\mathbf{H}\)</span> es un operador
arbitrario sobre una imagen cuya representación matricial es
<span class="math notranslate">\(f(m, n)\)</span> si satisface:</p>
<div class="math notranslate">
\[\begin{aligned}
    \mathbf{H} \left[ f(m, n) \right] = g(m, n)
\label{EqXXXV}\end{aligned}\]</div>
<p>Además, <span class="math notranslate">\(\mathbf{H}\)</span> es un operador lineal si:</p>
<div class="math notranslate">
\[\begin{aligned}
    \mathbf{H} \left[ \sum _{j} \alpha_{j} f_{j}(m, n) \right] = \sum _{j} \alpha_{j} \; \mathbf{H} \left[ f_{j}(m, n) \right]
\label{EqXXXVI}\end{aligned}\]</div>
<p>Una aplicación importante de las propiedades de linealidad de operadores
sobre imágenes es la descripción de imágenes <span class="math notranslate">\(g(m, n)\)</span> como
contribución “original” (<span class="math notranslate">\(f(m, n)\)</span>) y ruido <em>random</em>
(<span class="math notranslate">\(r(m, n)\)</span>):</p>
<div class="math notranslate">
\[\begin{aligned}
    g(m, n) = f(m, n) + r(m, n)
\label{EqXXXVII}\end{aligned}\]</div>
<p>La imagen de ruido es de tipo <em>random</em> si los valores de <em>pixels</em> de
<span class="math notranslate">\(r(m, n)\)</span> son aleatorios no correlacionados y con esperanza 0.</p>
<p>Promediando <span class="math notranslate">\(N_{Tot}\)</span> imágenes con ruido <em>random</em> se obtiene la
imagen promedio <span class="math notranslate">\(\langle g \rangle\)</span> dada por:</p>
<div class="math notranslate">
\[\begin{aligned}
    \langle g \rangle (m, n) = \frac{1}{N_{Tot}} \sum _{j=1} ^{N_{Tot}} g_{j} (m, n)
\label{EqXXXVIII}\end{aligned}\]</div>
<p>La aplicación del teorema del límite central establece que la imagen
promedio <span class="math notranslate">\(\langle g \rangle (m, n) \; \rightarrow f(m, n)\)</span> (imagen
“original”) para <span class="math notranslate">\(N_{Tot} \rightarrow \infty\)</span>.</p>
<p>Otra aplicación útil de los operadores lineales es la substracción de
una máscara <a class="footnote-reference" href="#id10" id="id4">[4]</a> <span class="math notranslate">\(M(m, n)\)</span> a la imagen original <span class="math notranslate">\(f(m, n)\)</span>:</p>
<div class="math notranslate">
\[\begin{aligned}
    g (m, n) = f(m, n) - M(m, n)
\label{EqXXXIX}\end{aligned}\]</div>
<div class="section" id="adicion-y-diferencia-de-imagenes">
<h3>Adición y diferencia de imágenes<a class="headerlink" href="#adicion-y-diferencia-de-imagenes" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Para ejemplificar las operaciones, se utilizan imágenes 8-bits.</p>
<p>Por tanto, los valores de la imagen resultado de la adición de dos
imágenes varían en <span class="math notranslate">\([0, 510]\)</span>. Mientras que los valores de la
imagen resultado de la diferencia de dos imágenes varían en
<span class="math notranslate">\([-255, 255]\)</span>.</p>
<p>La adecuación (<span class="math notranslate">\(f_{A}\)</span>) de los valores de la imagen resultado de
adición/diferencia de dos imágenes se realiza del siguiente modo:</p>
<div class="math notranslate">
\[\begin{aligned}
    f_{A} (m, n) = round \left[ \left( 2^{N} - 1 \right)
                \frac{f(m, n) - min{ \left[ f(m, n) \right] }}{max{ \left[ f(m, n) - min{f(m, n)} \right] }} \right]
\label{EqXL}\end{aligned}\]</div>
<p>Para imágenes de tipo <span class="math notranslate">\(N\)</span>-bits.</p>
</div>
</div>
<div class="section" id="operaciones-sobre-pixels">
<h2>Operaciones sobre pixels<a class="headerlink" href="#operaciones-sobre-pixels" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La introducción de operaciones espaciales que se llevan a cabo sobre los
valores de <em>pixels</em> de la imagen permiten:</p>
<ul class="simple">
<li>Operaciones de un <em>pixel</em>.</li>
<li>Operaciones de vecindad.</li>
<li>Transformaciones geométricas.</li>
</ul>
<p>Operaciones de un <em>pixel</em></p>
<p>Se modifica el valor de un <em>pixel</em> de modo individual en la imagen
original <span class="math notranslate">\(f(m, n)\)</span>, dando como resultado <span class="math notranslate">\(g(m, n)\)</span> dado por:</p>
<div class="math notranslate">
\[\begin{aligned}
    g (m, n) = \mathbf{T} \left( f(m, n) \right)
\label{EqXLI}\end{aligned}\]</div>
<p>de manera que el valor de imagen es modificado por la transformación
<span class="math notranslate">\(\mathbf{T}\)</span>. Este concepto se aplica, por ejemplo, para
determinar “el negativo”</p>
<p>Operaciones de vecindad</p>
<p>Sea <span class="math notranslate">\(C (M, N)\)</span> un conjunto de <em>pixels</em>
(<span class="math notranslate">\(M := [m_{min}, m_{max}]\)</span> y <span class="math notranslate">\(N := [n_{min}, n_{max}]\)</span>)
entorno (vecinos) al <em>pixel</em> <span class="math notranslate">\((m, n)\)</span>.</p>
<p>A partir de este tipo de operaciones de vecinos puede calcularse, por
ejemplo, el valor medio en un entorno rectangular (<span class="math notranslate">\(M \times N\)</span>)
de un <em>pixel</em> de interés <a class="footnote-reference" href="#id11" id="id5">[5]</a>. Resulta:</p>
<div class="math notranslate">
\[\begin{aligned}
    g (m, n) = \frac{1}{ M \; N} \sum _{(i, j) \in C(M, N)} f(i, j)
\label{EqXLII}\end{aligned}\]</div>
<p>Transformaciones geométricas.</p>
<p>Las transformaciones geométricas <span class="math notranslate">\(\mathbf{T}\)</span> de una image
<span class="math notranslate">\(f(m, n)\)</span> puede obtenerse a partir de una transformación de índole
geométrico de coordenadas espaciales: al valor del <em>pixel</em>
<span class="math notranslate">\((m, n)\)</span> se asigna el valor de un <em>pixel</em> <span class="math notranslate">\((i, j)\)</span>.</p>
<p>Debido a la naturaleza discreta de la representación de imágenes, debe
considerarse el proceso de interpolación para obtener los valores de
<em>pixels</em> como resultado de aplicar l transformación <span class="math notranslate">\(\mathbf{T}\)</span>.</p>
<p>Una de las categorías principales de los operadores de transformación
son las transformaciones denominadas afines, que incluyen translaciones,
rotaciones, escalados, reflexiones y proyecciones, entre otros.</p>
<p>Algunos ejemplos de operadores de transformación son:</p>
<ul class="simple">
<li>Rotación:
<span class="math notranslate">\(\mathbf{T_{Rot}} = \begin{array}{cc} \cos(\theta) &amp; \sin(\theta)  \\  -\sin(\theta) &amp; \cos(\theta) \\ \end{array}\)</span></li>
<li>Escaleo:
<span class="math notranslate">\(\mathbf{T_{Esc}} = \begin{array}{cc} e_{i} &amp; 0  \\  0 &amp; e_{j} \\ \end{array}\)</span></li>
<li>Traslación:
<span class="math notranslate">\(\mathbf{T_{Tra}} = \begin{array}{ccc} 1 &amp; 0 &amp; 0 \\  0 &amp; 1 &amp; 0 \\ t_{i} &amp; t_{j} &amp; 0 \\ \end{array}\)</span></li>
</ul>
</div>
<div class="section" id="transformadas-dicretas-la-transformada-de-fourier">
<h2>Transformadas dicretas: La transformada de Fourier<a class="headerlink" href="#transformadas-dicretas-la-transformada-de-fourier" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Desde un punto de vista general, las transformadas constituyen
operaciones espaciales sobre una imagen original <span class="math notranslate">\(f(m, n)\)</span>,
representada en el dominio espacial (que se refiere a las coordenadas
<span class="math notranslate">\((m, n)\)</span>) y una imagen resultado <span class="math notranslate">\(F(m, n)\)</span> que procesan los
valores de <em>pixels</em> en el plano geométrico.</p>
<p>Existen diferentes modos de representar de la imagen, en términos del
espacio ce representación:</p>
<ol class="arabic simple">
<li>la imagen <span class="math notranslate">\(f(m, n)\)</span> es representada por una matriz
<span class="math notranslate">\(M \times N\)</span> de <em>pixels</em> <span class="math notranslate">\((m, n)\)</span> discretos.</li>
<li>la imagen <span class="math notranslate">\(F(m*, n*)\)</span> es representada por una matriz
<span class="math notranslate">\(M \times N\)</span> de variables transformadas <span class="math notranslate">\((m*, n*)\)</span>.</li>
</ol>
<p>Como se introdujo de modo cualitativo (<a class="reference external" href="#EqXXV">[EqXXV]</a> y
<a class="reference external" href="#EqXXVI">[EqXXVI]</a>), una transformación lineal de una imagen
original <span class="math notranslate">\(f(m, n)\)</span> significa‘:</p>
<div class="math notranslate">
\[\begin{aligned}
    F (m*, n*) = \sum _{m} \sum _{n} f(m, n) \, k(m \; m*, n \; n*)
\label{EqXLIII}\end{aligned}\]</div>
<p>donde <span class="math notranslate">\(k\)</span> es el <em>kernel</em> de la transformación.</p>
<p>La transformada directa (<em>fordward</em>) de <span class="math notranslate">\(f(m, n)\)</span> deviene en
<span class="math notranslate">\(F(m*, n*)\)</span>, y la transformada inversa (<em>inverse</em>) de
<span class="math notranslate">\(F(m*, n*)\)</span> deviene en <span class="math notranslate">\(f(m, n)\)</span>. Por tanto, el equivalente
a la expresión (<a class="reference external" href="#EqXLIII">[EqXLIII]</a>) es:</p>
<div class="math notranslate">
\[\begin{aligned}
    f (m, n) = \sum _{m*} \sum _{n*} F(m*, n*) \, k(m* \; m, n* \; n)
\label{EqXLIV}\end{aligned}\]</div>
<p>donde <span class="math notranslate">\(k(m* \; m, n* \; n)\)</span> es el <em>kernel</em> de la transformación
inversa.</p>
<p>De este modo, se habilita la posibilidad de operar en el espacio de la
transformada. Es decir:</p>
<div class="math notranslate">
\[\begin{aligned}
    f (m, n) \; \underrightarrow{\mathbf{T}} \; \; F(m*, n*) \; \underrightarrow{\mathbf{O}} \; \; G(m*, n*) \;
    \underrightarrow{\mathbf{T^{-1}}} \; \; g(m, n)
\label{EqXLV}\end{aligned}\]</div>
<p>donde <span class="math notranslate">\(\mathbf{T}\)</span> y <span class="math notranslate">\(\mathbf{T^{-1}}\)</span> representan la
transformada directa e inversa, respectivamente. <span class="math notranslate">\(\mathbf{O}\)</span> es
un operador arbitrario.</p>
<p>Resulta de particular importancia la propiedad de los <em>kernels</em> de ser
separable en variables. Es decir:</p>
<div class="math notranslate">
\[\begin{aligned}
    k (m \; m*, n \; n*) = k_{(m, n)} (m, n) \;  k_{(m*, n*)} (m*, n*)
\label{EqXLVI}\end{aligned}\]</div>
<p>La transformada discreta de Fourier bidimensional 2D se define a partir
de los <em>kernels</em> de transformación:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    k_{TF} (m \; m*, n \; n*) = e^{-2 \pi i \left( \frac{m \, m*}{M} + \frac{n \, n*}{N}\right)} \nonumber \\
    k_{(TF)^{-1}} (m \; m*, n \; n*) = \frac{1}{M \, N}e^{2 \pi i \left( \frac{m \, m*}{M} + \frac{n \, n*}{N}\right)}
\label{EqXLVII}\end{aligned}\end{split}\]</div>
<p>Por tanto, la operación de transformadas discretas directa
(<span class="math notranslate">\(\mathbf{TF}\)</span>) e inversa (<span class="math notranslate">\(\mathbf{(TF)^{-1}}\)</span>) resultan:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    F(m*, n*) = \sum _{m} ^{M-1} \sum _{n} ^{N-1} f(m, n) \; e^{-2 \pi i \left( \frac{m \, m*}{M} + \frac{n \, n*}{N}\right)} \nonumber \\
    f(m, n) = \frac{1}{M \, N} \sum _{m*} ^{M-1} \sum _{n*} ^{N-1} F(m*, n*) \; e^{2 \pi i \left( \frac{m \, m*}{M} + \frac{n \, n*}{N}\right)}
\label{EqXLVIII}\end{aligned}\end{split}\]</div>
<p>Cuyo análogo en espacios continuos es:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    F(u, v) = \mathbf{TF}[f(x, y)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x, y) \; e^{-2 \pi \i (u \, x + v \, y)} \; dx dy \nonumber \\
    f(x, y) = \mathbf{(TF)^{-1}}[F(u, v)] = \frac{1}{4 \pi^{2}} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} F(u, v) \;
    e^{2 \pi i (u \, x + v \, y)} \; du dv
\label{EqLI}\end{aligned}\end{split}\]</div>
<p>La expresión (<a class="reference external" href="#EqXLIX">[EqXLIX]</a>) para la transformada de Fourier
puede interpretarse, dejando de lado momentaneamente problemas de
existencia y unicidad, como una suma de exponenciales complejas con
pesos para los términos, donde las variables <span class="math notranslate">\(m*\)</span> y <span class="math notranslate">\(n*\)</span>
representan las frecuencias en el dominio de la transformada.</p>
<p>El valor de la transformada en <span class="math notranslate">\((m*, n*)\)</span> (<span class="math notranslate">\(F(m*, n*)\)</span>)
contribuye a través de
<span class="math notranslate">\(F(m*, n*) \, e^{2 \pi i (u \, x + v \, y)}\)</span> y puede verse, ya que
<span class="math notranslate">\(f(m, n)\)</span> es una función real, que
<span class="math notranslate">\(F(m*, n*) = F^{\prime} (m*, n*)\)</span>, donde <span class="math notranslate">\(\prime\)</span> indica el
complejo conjugado.</p>
<p>A modo de ejemplo, la figuras <a class="reference external" href="#Fig2_3">[Fig2_3]</a>,
<a class="reference external" href="#Fig2_4">[Fig2_4]</a> y <a class="reference external" href="#Fig2_5">[Fig2_5]</a> presentan resultados de
aplicar la transformada de Fourier de la imagen orifinal <span class="math notranslate">\(f(m, n)\)</span>
para diferentes casos.</p>
<div class="figure align-center" id="id16">
<img alt="_images/Fig2_3.png" src="_images/Fig2_3.png" />
<p class="caption"><span class="caption-text"><strong>Figura 4:</strong> Ejemplo de transformada de Fourier:
<span class="math notranslate">\(f(m, n) = 0\)</span>; <span class="math notranslate">\(\forall (m, n) \neq (51, 51)\)</span>;  <span class="math notranslate">\(m, n \in [1, 101]\)</span>
obtenido con plataforma MatLab <a class="footnote-reference" href="#id12" id="id6">[*]</a>.</span></p>
</div>
<div class="figure align-center" id="id17">
<img alt="_images/Fig2_4.png" src="_images/Fig2_4.png" />
<p class="caption"><span class="caption-text"><strong>Figura 5:</strong> Ejemplo de transformada de Fourier:
<span class="math notranslate">\(f(m, n) = 0\)</span>; <span class="math notranslate">\(\forall (m, n) \neq (40, 51)\)</span>, <span class="math notranslate">\(\vee \neq (60, 51)\)</span>; <span class="math notranslate">\(m, n \in [1, 101]\)</span> obtenido con plataforma MatLab.</span></p>
</div>
<div class="figure align-center" id="id18">
<img alt="_images/Fig2_5.png" src="_images/Fig2_5.png" />
<p class="caption"><span class="caption-text"><strong>Figura 6:</strong> Ejemplo de transformada de Fourier:
<span class="math notranslate">\(f(m, n) = 0\)</span>; <span class="math notranslate">\(\forall (m, n) \neq (51, 40)\)</span>, <span class="math notranslate">\(\vee \neq (51, 60)\)</span>; <span class="math notranslate">\(m,n \in [1, 101]\)</span> obtenido con plataforma MatLab.</span></p>
</div>
</div>
<div class="section" id="filtros">
<h2>Filtros<a class="headerlink" href="#filtros" title="Enlazar permanentemente con este título">¶</a></h2>
<p>A partir de las definiciones introducidas por las expresiones
(<a class="reference external" href="#EqL">[EqL]</a>) y (<a class="reference external" href="#EqLI">[EqLI]</a>) resulta posible realizar
procesos de filtrado tanto en el dominio especial de la imagen original
<span class="math notranslate">\(f(m, n)\)</span> como en el dominio de las frecuencias de la transformada
<span class="math notranslate">\(F(m*, n*)\)</span>.</p>
<p>Una característica significativa, que representa de hecho una de las
principales ventajas de los espacios de transformadas, es que la
operación de filtrado se realiza por medio de una multiplicación de
transformadas; mientras que la operación en el espacio de coordenadas
significa una convolución denotada por el símbolo <span class="math notranslate">\(\otimes\)</span>. En
virtud del teorema de convolución, se tiene:</p>
<div class="math notranslate">
\[\begin{aligned}
    f(m, n) \otimes g(m, n) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(m, n) \; g(m-k, n-l)\; dk \, dl
\label{EqLII}\end{aligned}\]</div>
<p>Aplicando la definición de transformada de Fourier, se obtiene:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    F_{f, g}(m*, n*) \equiv \mathbf{TF} [ f(m, n) \otimes g(m, n) ] =  \nonumber \\
    \mathbf{TF} [ f(m, n)] \; \mathbf{TF} [ g(m, n)] = F(m*, n*) \; G(m*, n*)
\label{EqLIII}\end{aligned}\end{split}\]</div>
<p>Para una dada función original <span class="math notranslate">\(f(m, n)\)</span> y su correspondiente
transformada de Fourier <span class="math notranslate">\(F(m*, n*)\)</span>, en referencia a la expresión
(<a class="reference external" href="#EqLIII">[EqLIII]</a>) el operador <span class="math notranslate">\(G(m*, n*)\)</span> se define como un
<em>filtro espacial lineal</em> o <em>función de transferencia</em> de filtro.</p>
<p>Entonces, la imagen resultado del proceso de filtrado <span class="math notranslate">\(h(m, n)\)</span> se
obtiene aplicando la transformada inversa:</p>
<div class="math notranslate">
\[\begin{aligned}
    h(m, n) = \mathbf{TF^{-1}} [F_{f, g}(m*, n*) ]
\label{EqLIV}\end{aligned}\]</div>
<p>El filtro queda determinado por medio de la función de transferencia o
bien por la <em>respuesta de impulso</em> <span class="math notranslate">\(j(m, n)\)</span> definida a partir de:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    j(m, n) = F_{f, g}(m, n) = \delta (m, n) \otimes j(m, n) =  \nonumber \\
    \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \delta(m, n) \, j(k-m, l-n) \; dk \, dl
\label{EqLV}\end{aligned}\end{split}\]</div>
<p>Resulta que <span class="math notranslate">\(j(m, n)\)</span> es un filtrado intenso en términos de la
función <span class="math notranslate">\(\delta\)</span> de Dirac.</p>
<p>A fines de cómputo, la transformada discreta de Fourier puede obtenerse,
en modo análogo a la expresión (<a class="reference external" href="#EqXLVIII">[EqXLVIII]</a>) operando:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    F(m^*, n^*) = \mathbf{TF}[f(m, n)] = \frac{1}{M \, N} \sum_{m=0}^{M-1} \sum_{n=0}^{N-1} f(m, n) \; \nonumber \\
    \left[ \cos \left( 2 \pi  (\frac{m^* \, m}{M} + \frac{n^* \, n}{N}) \right) +
    i \, \sin \left( 2 \pi  (\frac{m^* \, m}{M} + \frac{n^* \, n}{N}) \right)\right] \nonumber \\
    f(m, n) = \mathbf{TF^{-1}} [F(m^*, n^*)] = \sum_{m=0}^{M-1} \sum_{n=0}^{N-1} F(m^*, n^*) \; \nonumber \\
    \left[ \cos \left( -2 \pi  (\frac{m^* \, m}{M} + \frac{n^* \, n}{N}) \right) -
    i \, \sin \left( 2 \pi  (\frac{m^* \, m}{M} + \frac{n^* \, n}{N}) \right)\right] \nonumber \\
\label{EqLVI}\end{aligned}\end{split}\]</div>
<p>Debido a la naturaleza discreta del espacio de muestreo intrínseco al
procesamiento digital de imágenes, se determina la relación entre
dominios espaciales y de frecuencias por medio de:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    \Delta m^* = \frac{1}{M\; \Delta m}  \\
    \Delta n^* = \frac{1}{N\; \Delta n}
\label{EqLVII}\end{aligned}\end{split}\]</div>
<p>Cabe destacar que, por conveniencia de procesamiento, para el caso de
imágenes “cuadradas” para las que <span class="math notranslate">\(N = M\)</span>, se redefine la
expresión para la transformada de Fourier, multuplicando la expresión
(<a class="reference external" href="#EqLVI">[EqLVI]</a>) por <span class="math notranslate">\(N\)</span>, es decir:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    F(m^*, n^*) = \mathbf{TF}[f(m, n)] = \frac{1}{N} \sum_{m=0}^{N-1} \sum_{n=0}^{N-1} f(m, n) \;
    e^{-2 \pi \, i \, \left( \frac{m^* \, m + n^* \, n}{N} \right)} \nonumber \\
    f(m, n) = \mathbf{TF^{-1}} [F(m^*, n^*)] = \frac{1}{N} \sum_{m=0}^{N-1} \sum_{n=0}^{N-1} F(m^*, n^*) \;
    e^{2 \pi \, i \, \left( \frac{m^* \, m + n^* \, n}{N} \right)} \nonumber \\
\label{EqLVIII}\end{aligned}\end{split}\]</div>
<p>La componente espectral compleja de <span class="math notranslate">\(F(m^*, n^*)\)</span> determina módulo
y fase, respectivamente, dados por:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    \lvert F(m^*, n^*) \rvert = \sqrt{\left[ \Re{ \left( F(m^*, n^*) \right) }\right]^{2} +
    \left[ \Im{\left( F(m^*, n^*) \right) } \right]^{2}} \nonumber \\
    \phi(m^*, n^*) = \arctan \left[ \frac{\Im{\left( F(m^*, n^*) \right) }}{\Re{\left( F(m^*, n^*) \right) }}\right]
\label{EqLIX}\end{aligned}\end{split}\]</div>
<p>donde <span class="math notranslate">\(\Im\)</span> y <span class="math notranslate">\(\Re\)</span> representan las componentes imaginaria y
real, respectivamente. Al filtrar una imagen original cuadrada
<span class="math notranslate">\(f(m, n)\)</span> de dimensiones <span class="math notranslate">\(N \times N\)</span> mediante un filtro
<span class="math notranslate">\(j(m, n)\)</span> de dimensiones <span class="math notranslate">\(L \times L\)</span> se obtendrá una imagen
resultado <span class="math notranslate">\(g(m, n)\)</span> de dimensiones
<span class="math notranslate">\(N + L -1 \; \; \times \; \; N + L -1\)</span>.</p>
<p>Las propiedades de la transformada de Fourier permiten identificar de
modo sencillo los operadores más relevantes del procesamiento digital,
como:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    f(m, n)e^{2 \pi \, i (\frac{m^* _{0} \, m + n^* _{0} \, n}{N})} \leftrightarrow F(m^* - m^* _{0}, n^* - n^* _{0}) \\
    f(m - m_{0}, n - n_{0}) \leftrightarrow F(m^*, n^*) \, e^{-2 \pi \, i (\frac{m^* \, m_{0} + n^* \, n_{0}}{N})} \nonumber
\label{EqLX}\end{aligned}\end{split}\]</div>
<p>Es decir, una traslación al punto <span class="math notranslate">\((m_{0}, n_{0})\)</span> se identifica
con con el corrimiento del origen del plano del dominio de frecuencias
al punto <span class="math notranslate">\((m^*_{0}, n^*_{0})\)</span>.</p>
<p>En coordenadas polares
<span class="math notranslate">\(m = \rho \, \cos{\theta} \; \; n = \rho \, \sin{\theta} \; \; m^* = \omega \, \cos{\phi} \; \; n^* = \omega \, \sin{\phi}\)</span>,
las imágenes original <span class="math notranslate">\(f(m, n)\)</span> y transformada <span class="math notranslate">\(F(m^*, n^*)\)</span>
son expresadas como <span class="math notranslate">\(f(\rho, \theta)\)</span> y <span class="math notranslate">\(F(\omega, \phi)\)</span>.</p>
<p>Aplicando la definición de transformada de Fourier, resulta:</p>
<div class="math notranslate">
\[\begin{aligned}
    f(\rho, \theta + \theta_{0}) \leftrightarrow F(\omega, \phi + \theta_{0})
\label{EqLXI}\end{aligned}\]</div>
<p>Es decir, la rotación de la imagen original <span class="math notranslate">\(f(\rho, \theta)\)</span> (o
<span class="math notranslate">\(f(m, n)\)</span>) por un ángulo <span class="math notranslate">\(\theta_{0}\)</span> se vincula con una
rotación del mismo ángulo en la imagen resultante
<span class="math notranslate">\(F(\omega, \phi)\)</span> (o <span class="math notranslate">\(F(m^*, n^*)\)</span>).</p>
<p>Las figuras <a class="reference external" href="#Fig2_6">[Fig2_6]</a> y <a class="reference external" href="#Fig2_7">[Fig2_7]</a> muestran
ejemplos de aplicación de operadores de rotación, en dominio de
coordenadas y de frecuencias, respectivamente.</p>
<div class="figure align-center" id="id19">
<img alt="_images/Fig2_6.png" src="_images/Fig2_6.png" />
<p class="caption"><span class="caption-text"><strong>Figura 7:</strong> Rotación de <span class="math notranslate">\(35^{\deg}\)</span> de una imagen original <span class="math notranslate">\(f(m, n)\)</span>
(o <span class="math notranslate">\(f(\rho, \theta)\)</span>) obtenido con plataforma MatLab.</span></p>
</div>
<div class="figure align-center" id="id20">
<img alt="_images/Fig2_7.png" src="_images/Fig2_7.png" />
<p class="caption"><span class="caption-text"><strong>Figura 8:</strong> Rotación de <span class="math notranslate">\(35^{\deg}\)</span> de una imagen en dominio de transformada
<span class="math notranslate">\(F(m^*, n^*)\)</span> (o <span class="math notranslate">\(F(\omega, \phi)\)</span>) obtenido con plataforma MatLab.</span></p>
</div>
<p><strong>Operador de Escaleo</strong></p>
<p>La definición de transformada de Fourier implica que <span class="math notranslate">\(\mathbf{TF} [f_{A}(m, n) + f_{B}(m, n)] = \mathbf{TF} [f_{A}(m, n)] + \mathbf{TF}[f_{B}(m, n)]\)</span> pero <span class="math notranslate">\(\mathbf{TF} [f_{A}(m, n) \cdot f_{B}(m, n)] \neq \mathbf{TF} [f_{A}(m, n)] \cdot \mathbf{TF}[f_{B}(m, n)]\)</span>.</p>
<p>Sin embargo, para escalares <span class="math notranslate">\(\alpha\)</span> y <span class="math notranslate">\(\beta\)</span> se tiene:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    \alpha \, f(m, n) \leftrightarrow \alpha \, F(m^*, n^*) \\
    f(\alpha m, \beta n) = \frac{1}{\lvert \alpha \beta \rvert}
    F(\alpha \, m^*, \beta \, n^*)
\label{EqLXII}\end{aligned}\end{split}\]</div>
<p><strong>Cálculo de promedios</strong></p>
<p>El valor medio <span class="math notranslate">\(\langle f \rangle\)</span> se obtiene a partir de:</p>
<div class="math notranslate">
\[\begin{aligned}
    \langle f \rangle = \frac{1}{N^2} \sum _{m=0}^{N-1} \sum _{n=0}^{N-1} f(m, n)
\label{EqLXIII}\end{aligned}\]</div>
<p>En particular, tomando <span class="math notranslate">\(F(m^*=0, n^*=0)\)</span> en la expresión
(<a class="reference external" href="#EqLIX">[EqLIX]</a> (59)) se obtiene
<span class="math notranslate">\(F(0, 0)= \frac{1}{N} \sum _{m=0}^{N-1} \sum _{n=0}^{N-1} f(m, n)\)</span>.
Por lo tanto, el valor promedio puede calcularse directamente a partir
de:</p>
<div class="math notranslate">
\[\begin{aligned}
    \langle f \rangle = \frac{1}{N} F(m^* = 0, n^* = 0)
\label{EqLXIV}\end{aligned}\]</div>
<p><strong>Cálculo de operadores de derivadas: OPerador de Laplace</strong></p>
<p>La laplaciana <span class="math notranslate">\(\nabla^2\)</span> de una imagen original <span class="math notranslate">\(f(m, n)\)</span>
está dada por:</p>
<div class="math notranslate">
\[\begin{aligned}
    \nabla^2 f(m, n) \equiv \frac{\partial^2}{\partial m^2} + \frac{\partial^2}{\partial n^2}
\label{EqLXV}\end{aligned}\]</div>
<p>Aplicando la definición de transformada de Fourier, se obtiene una
expresión útil para el cálculo de la Laplaciana:</p>
<div class="math notranslate">
\[\begin{aligned}
    \mathbf{TF}[ \nabla^2 f(m, n) ] = -(2 \pi)^2 \left[ (m^*) ^2 + (n^*) ^2 \right] \; F(m^*, n^*)
\label{EqLXVI}\end{aligned}\]</div>
<div class="section" id="filtros-de-paso-de-banda">
<h3>Filtros de paso de banda<a class="headerlink" href="#filtros-de-paso-de-banda" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Las transiciones abruptas, como bordes y contornos, en una imagen
original <span class="math notranslate">\(f(m, n)\)</span> se corresponden con altas frecuencias en el
dominio de la transformada.</p>
</div>
<div class="section" id="filtros-de-suavizado">
<h3>Filtros de suavizado<a class="headerlink" href="#filtros-de-suavizado" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Puede aprovecharse esta característica para implementar métodos de
filtrado para suavizar operando en el dominio de frecuencias.</p>
<p>Es posible suprimir frecuencias por debajo o por encima de valores pre
determinados de manera que se produzcan efectos de suavizado según
requerimientos.</p>
<p><strong>Filtros ideal de paso alto</strong></p>
<p>Consiste en la utilización de la expresión (<a class="reference external" href="#EqLIII">[EqLIII]</a>) con
la función de transferencia <span class="math notranslate">\(G_{P,A}(m^*, n^*)\)</span> definida por:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    G_{P,A}(m^*, n^*) = \left\{ \begin{array}{ll}
    0 &amp; \mbox{$D(m^*, n^*) \leq D_{max}$}\\
    1 &amp; \mbox{$D(m^*, n^*) &gt; D_{max}$}.\end{array} \right.
\label{EqLXVII}\end{aligned}\end{split}\]</div>
<p>Para un valor máximo de distancia <span class="math notranslate">\(D_{max}\)</span> como umbral para la
distancia (independientemente de la métrica), <span class="math notranslate">\(D(m^*, n^*)\)</span> es la
distancia al origen de frecuencias <span class="math notranslate">\((m^* = 0, n^* = 0)\)</span>.</p>
<p>En el caso de la métrica Euclidea
<span class="math notranslate">\(D(m^*, n^*) = \sqrt{ (m^*)^2 + (n^*)^2}\)</span>, el filtro se representa
por un círculo de radio <span class="math notranslate">\(D_{max}\)</span> como muestra la figura
<a class="reference external" href="#Fig2_8">[Fig2_8]</a>.</p>
<div class="figure align-center" id="id21">
<img alt="_images/Fig2_8.png" src="_images/Fig2_8.png" />
<p class="caption"><span class="caption-text"><strong>Figura 9:</strong> Matriz de transferencia <span class="math notranslate">\(G_{P\,A}\)</span> para un filtro ideal de paso
alto obtenida con plataforma MatLab.</span></p>
</div>
<p><strong>Filtros ideal de paso bajo</strong></p>
<p>De modo análogo, para el caso del filtro de paso bajo se define a partir
de la matriz de transferencia <span class="math notranslate">\(G_{P,B}\)</span> dada por:</p>
<div class="math notranslate">
\[\begin{split}\begin{aligned}
    G_{P,B}(m^*, n^*) = \left\{ \begin{array}{ll}
    1 &amp; \mbox{$D(m^*, n^*) \leq D_{max}$}\\
    0 &amp; \mbox{$D(m^*, n^*) &gt; D_{max}$}.\end{array} \right.
\label{EqLXVIII}\end{aligned}\end{split}\]</div>
<p>La figura <a class="reference external" href="#Fig2_9">[Fig2_9]</a> muestra la matriz de transferencia de
paso bajo <span class="math notranslate">\(G_{P\,B}\)</span>.</p>
<div class="figure align-center" id="id22">
<img alt="_images/Fig2_9.png" src="_images/Fig2_9.png" />
<p class="caption"><span class="caption-text"><strong>Figura 10:</strong> Matriz de transferencia <span class="math notranslate">\(G_{P\,B}\)</span> para un filtro ideal de paso
alto obtenida con plataforma MatLab.</span></p>
</div>
</div>
<div class="section" id="mascaras-para-filtrado">
<h3>Máscaras para filtrado<a class="headerlink" href="#mascaras-para-filtrado" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Una máscara de filtrado <span class="math notranslate">\(h(m, n)\)</span> se denomina máscara de
convolución espacial si se define pormedio de:</p>
<div class="math notranslate">
\[\begin{aligned}
    F(m^*, n^*) = \frac{1}{N} \sum _{m=0}^{N-1} \sum _{m=0}^{N-1} h(m, n) \, e^{-2 \pi i \left( \frac{m^* \, m + n^* \, n}{N} \right)}
\label{EqLXIX}\end{aligned}\]</div>
<p>Si la máscara se restringue a una región específica, tal que
<span class="math notranslate">\(h(m, n) = 0\)</span> para <span class="math notranslate">\(m \wedge n \ge N_{max} &lt; N\)</span> de modo que
la máscara restringida sea designada por <span class="math notranslate">\(\hat{h}\)</span>, se obtiene:</p>
<div class="math notranslate">
\[\begin{aligned}
    \hat{H}(m^*, n^*) = \frac{1}{N} \sum _{n=0}^{N_{max}-1} \sum _{m=0}^{N_{max}-1} \hat{h}(m, n) \,
    e^{-2 \pi i \left( \frac{m^* \, m + n^* \, n}{N} \right)}
\label{EqLXX}\end{aligned}\]</div>
<p>De modo que puedan determinarse los coeficientes de la expansión en
(<a class="reference external" href="#EqLXX">[EqLXX]</a>) que de minimizar la cantidad:</p>
<div class="math notranslate">
\[\begin{aligned}
    \chi^2 \equiv \sum _{m^*=0}^{N-1} \sum _{n^*=0}^{N-1} \lvert \hat{H}(m^*, n^*) - H(m^*, n^*) \rvert^2
\label{EqLXXI}\end{aligned}\]</div>
<p>La expresión anterior (<a class="reference external" href="#EqLXXI">[EqLXXI]</a>) puede resolverse por
medio de una representación algebraica lineal
<span class="math notranslate">\(\mathbf{\hat{H}} = \mathbf{Q} \, \mathbf{\hat{h}}\)</span> con
<span class="math notranslate">\(\mathbf{\hat{H}}\)</span> representado por un vector de dimensión
<span class="math notranslate">\(N^2\)</span> cuyos elementos son los de <span class="math notranslate">\(\hat{H}\)</span> ordenados de
algún modo arbitrario, <span class="math notranslate">\(\mathbf{\hat{h}}\)</span> es un vector columna de
dimensiones <span class="math notranslate">\(N_{max}^2\)</span> conteniendo los elementos de
<span class="math notranslate">\(\hat{h}\)</span> y <span class="math notranslate">\(\mathbf{Q}\)</span> es una matriz de dimensiones
<span class="math notranslate">\(N^2 \times N_{max}^2\)</span> de términos exponenciales de acuerdo con la
expresión (<a class="reference external" href="#EqLXIX">[EqLXIX]</a>) dados por:</p>
<div class="math notranslate">
\[\begin{aligned}
    \mathbf{Q}(k, l) = q(k, l) = \frac{1}{N} e^{-2 \pi i \left( \frac{m^* \, m + n^* \, n}{N} \right)}
\label{EqLXXII}\end{aligned}\]</div>
<p>para <span class="math notranslate">\(k= m^* N + n^*\)</span> con <span class="math notranslate">\(m^* \wedge n^* \in [0, N-1]\)</span> y
<span class="math notranslate">\(l= m N_{max} + n\)</span> con <span class="math notranslate">\(m \wedge n \in [0, N_{max}-1]\)</span>.</p>
<table class="docutils footnote" frame="void" id="id7" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Se entiende como rayos X a aquellos producidos en interacciones
atómicas, y rayos <span class="math notranslate">\(\gamma\)</span> a aquellos producidos por
interacciones internucleares. No existe <em>a priori</em> diferencia
energética entre ellos y ambos son constituidos por fotones, la
diferencia se realiza a partir de su procedencia. En adelante se
utilizará indistintamente las letras X o <span class="math notranslate">\(\gamma\)</span> para
referirse a fotones.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id8" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>Este parámetro es denominado “umbral” y su valor condiciona la
<em>performance</em> de la técnica.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id9" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[3]</a></td><td>Aquí la función <em>floor</em> se define por medio de asignar al argumento
el número entero más grande que sea menor que el argumento.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4">[4]</a></td><td>Un ejemplo típico son las imágenes médicas por contraste, como
angiografías.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id5">[5]</a></td><td>Este método resulta de utilidad para suprimir detalles o realzar
regiones.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id12" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[*]</a></td><td>Official license MathWorks 3407-8985-4332-9223-7918.</td></tr>
</tbody>
</table>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="cap1.html" class="btn btn-neutral" title="Introducción al transporte de radiación" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, P. Pérez &amp; M. Valente.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>